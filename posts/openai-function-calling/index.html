<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Opensource Solution for OpenAI Function Calling | Matrix Engineering Blog</title>
<meta name="keywords" content="">
<meta name="description" content="Introduction to OpenAI Function Calling OpenAI rolled out a cool new feature called &ldquo;Function Calling.&rdquo; In coding, when you create a function, you usually have to list out the parameters (like integers, strings, enums) to pass to it. With &ldquo;Function Calling,&rdquo; you can now simply describe what you want and what action you want to take in plain language, and it will automatically figure them out and call the function for you.">
<meta name="author" content="">
<link rel="canonical" href="http://matrixstone.github.io/posts/openai-function-calling/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.bccfefac377bc340f06c260aed1bddf49a4354816d7c570d6aac75a997986c95.css" integrity="sha256-vM/vrDd7w0DwbCYK7Rvd9JpDVIFtfFcNaqx1qZeYbJU=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="http://matrixstone.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://matrixstone.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://matrixstone.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://matrixstone.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="http://matrixstone.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7F1EZQ04MV"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-7F1EZQ04MV', { 'anonymize_ip': false });
}
</script>
<meta property="og:title" content="Opensource Solution for OpenAI Function Calling" />
<meta property="og:description" content="Introduction to OpenAI Function Calling OpenAI rolled out a cool new feature called &ldquo;Function Calling.&rdquo; In coding, when you create a function, you usually have to list out the parameters (like integers, strings, enums) to pass to it. With &ldquo;Function Calling,&rdquo; you can now simply describe what you want and what action you want to take in plain language, and it will automatically figure them out and call the function for you." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://matrixstone.github.io/posts/openai-function-calling/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-06T22:54:46-08:00" />
<meta property="article:modified_time" content="2023-11-06T22:54:46-08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Opensource Solution for OpenAI Function Calling"/>
<meta name="twitter:description" content="Introduction to OpenAI Function Calling OpenAI rolled out a cool new feature called &ldquo;Function Calling.&rdquo; In coding, when you create a function, you usually have to list out the parameters (like integers, strings, enums) to pass to it. With &ldquo;Function Calling,&rdquo; you can now simply describe what you want and what action you want to take in plain language, and it will automatically figure them out and call the function for you."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://matrixstone.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Opensource Solution for OpenAI Function Calling",
      "item": "http://matrixstone.github.io/posts/openai-function-calling/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Opensource Solution for OpenAI Function Calling",
  "name": "Opensource Solution for OpenAI Function Calling",
  "description": "Introduction to OpenAI Function Calling OpenAI rolled out a cool new feature called \u0026ldquo;Function Calling.\u0026rdquo; In coding, when you create a function, you usually have to list out the parameters (like integers, strings, enums) to pass to it. With \u0026ldquo;Function Calling,\u0026rdquo; you can now simply describe what you want and what action you want to take in plain language, and it will automatically figure them out and call the function for you.",
  "keywords": [
    
  ],
  "articleBody": "Introduction to OpenAI Function Calling OpenAI rolled out a cool new feature called “Function Calling.” In coding, when you create a function, you usually have to list out the parameters (like integers, strings, enums) to pass to it. With “Function Calling,” you can now simply describe what you want and what action you want to take in plain language, and it will automatically figure them out and call the function for you. Handy, right?\nHere’s a clear example inherited from the OpenAI example: imagine we have a function called “get_current_weather(location).” If someone asks, “What’s the weather like in San Francisco, Tokyo, and Paris?” OpenAI can smartly identify that the “location” parameter for calling the function is [San Francisco, Tokyo, Paris].\nInitially, “Function Calling” may sound like something only engineers would appreciate. However, if you delve into it, APIs (which share input-output structures with functions) become apparent. Identifying the right function to call means knowing which API to use. Going further, services like ordering an Uber, searching online, or booking a hotel—they all function as “APIs.” That’s what makes “Function Calling” such a potent feature.\nOpen source Solution of Function Calling Given the abundance of open-source LLM models online, folks often opt to host these models independently rather than relying on OpenAI API for queries and billing. However, it’s worth noting that “Function Calling” isn’t a feature readily supported by most open-source LLM models. In this piece, I’ll discuss the prompt engineering approach I employed to enable function calling with an open-source LLM.\nModel: Mistral-7B-Instruct-v0.1 I experimented with the “mistralai/Mistral-7B-Instruct-v0.1” model. I opted for Mistral 7B because, as mentioned on the Mistral website, Mistral-7B-v0.1 is a small, yet powerful model adaptable to many use-cases. Mistral 7B is better than Llama 2 13B on all benchmarks, has natural coding abilities, and 8k sequence length.\nYou can test and verify the performance of this prompt with HuggingFace mistralai/Mistral-7B-Instruct-v0.1\nPrompt Structure Consider a straightforward example: a function designed to assist in booking tables at a restaurant. Picture the function as “book_table(restaurant_name: str, number_of_people: int, time: date, allergy: type(enum)).”\nBased on the requirement to book a restaurant, answer each question. `requirement: {natural language text}` Question 1: What is the name of the restaurant? Question 2: How many people mentioned in the requirement for booking? Question 3: At what time is this booking for? Question 4: Is there any type of allergy mentioned in the requirement? Choose from [milk, egg, fish, peanuts]. Return your responses in JSON format, using the question number as the key and the answer as the value. Explain\nIn the prompt, I start by giving a brief overview of the natural language text, setting the tone for the entire prompt or the system role. List Question #, very likely you will have multiple params to decide. For each question, I start with a description of the parameter itself. For instance, inquire about the restaurant’s name and the number of people mentioned for the booking. In each question, I started with a description of the param itself. For example, the name of the restaurant, how many people mentioned the booking. In the engineering world, the challenges are usually more intricate than the example we’re using here. This is because the parameters of a function are specific to the system itself, often not simple phrases easily understood by the literary word. Teaching LLM, to grasp the meaning or motivation behind these parameters requires careful consideration and is a critical step to success. If the expected values for a parameter are limited options, resembling a standard enum parameter, it’s essential to list the available selections. If necessary, explain the meaning of each value to ensure the LLM can distinguish between them and choose the right one. Simultaneously, list other requirements for this selection, such as a default value if needed or any dependencies on other questions. As is customary with LLMs, we encourage the model to return a JSON-formatted response. Issues to Improve Yet, the prompt engineering approach has its flaws. A recurring problem is hallucination. Despite instructing the LLM to choose a value from a specified list, it may still generate an unexpected value based on its own interpretation.\n",
  "wordCount" : "695",
  "inLanguage": "en",
  "datePublished": "2023-11-06T22:54:46-08:00",
  "dateModified": "2023-11-06T22:54:46-08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://matrixstone.github.io/posts/openai-function-calling/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Matrix Engineering Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "http://matrixstone.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://matrixstone.github.io/" accesskey="h" title="Matrix Engineering Blog (Alt + H)">Matrix Engineering Blog</a>
                    <div class="logo-switches">
                        <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                            <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                                fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                                stroke-linejoin="round">
                                <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                            </svg>
                            <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                                fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                                stroke-linejoin="round">
                                <circle cx="12" cy="12" r="5"></circle>
                                <line x1="12" y1="1" x2="12" y2="3"></line>
                                <line x1="12" y1="21" x2="12" y2="23"></line>
                                <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                                <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                                <line x1="1" y1="12" x2="3" y2="12"></line>
                                <line x1="21" y1="12" x2="23" y2="12"></line>
                                <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                                <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                            </svg>
                        </button>
                    </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header><main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      Opensource Solution for OpenAI Function Calling
    </h1>
    <div class="post-meta"><span title='2023-11-06 22:54:46 -0800 PST'>November 6, 2023</span>

</div>
  </header> 
  <div class="post-content"><h2 id="introduction-to-openai-function-calling">Introduction to OpenAI Function Calling<a hidden class="anchor" aria-hidden="true" href="#introduction-to-openai-function-calling">#</a></h2>
<p>OpenAI rolled out a cool new feature called &ldquo;Function Calling.&rdquo; In coding, when you create a function, you usually have to list out the parameters (like integers, strings, enums) to pass to it. With &ldquo;Function Calling,&rdquo; you can now simply describe what you want and what action you want to take in plain language, and it will automatically figure them out and call the function for you. Handy, right?</p>
<p>Here&rsquo;s a clear example inherited from the OpenAI example: imagine we have a function called &ldquo;get_current_weather(location).&rdquo; If someone asks, &ldquo;What&rsquo;s the weather like in San Francisco, Tokyo, and Paris?&rdquo; OpenAI can smartly identify that the &ldquo;location&rdquo; parameter for calling the function is [San Francisco, Tokyo, Paris].</p>
<p>Initially, &ldquo;Function Calling&rdquo; may sound like something only engineers would appreciate. However, if you delve into it, APIs (which share input-output structures with functions) become apparent. Identifying the right function to call means knowing which API to use. Going further, services like ordering an Uber, searching online, or booking a hotel—they all function as &ldquo;APIs.&rdquo; That&rsquo;s what makes &ldquo;Function Calling&rdquo; such a potent feature.</p>
<h2 id="open-source-solution-of-function-calling">Open source Solution of Function Calling<a hidden class="anchor" aria-hidden="true" href="#open-source-solution-of-function-calling">#</a></h2>
<p>Given the abundance of open-source LLM models online, folks often opt to host these models independently rather than relying on OpenAI API for queries and billing. However, it&rsquo;s worth noting that &ldquo;Function Calling&rdquo; isn&rsquo;t a feature readily supported by most open-source LLM models. In this piece, I&rsquo;ll discuss the prompt engineering approach I employed to enable function calling with an open-source LLM.</p>
<h3 id="model-mistral-7b-instruct-v01">Model: Mistral-7B-Instruct-v0.1<a hidden class="anchor" aria-hidden="true" href="#model-mistral-7b-instruct-v01">#</a></h3>
<p>I experimented with the &ldquo;mistralai/Mistral-7B-Instruct-v0.1&rdquo; model. I opted for Mistral 7B because, as mentioned on the Mistral website, Mistral-7B-v0.1 is a small, yet powerful model adaptable to many use-cases. Mistral 7B is better than Llama 2 13B on all benchmarks, has natural coding abilities, and 8k sequence length.</p>
<p>You can test and verify the performance of this prompt with <a href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1">HuggingFace mistralai/Mistral-7B-Instruct-v0.1</a></p>
<h3 id="prompt-structure">Prompt Structure<a hidden class="anchor" aria-hidden="true" href="#prompt-structure">#</a></h3>
<p>Consider a straightforward example: a function designed to assist in booking tables at a restaurant. Picture the function as &ldquo;book_table(restaurant_name: str, number_of_people: int, time: date, allergy: type(enum)).&rdquo;</p>
<pre tabindex="0"><code>Based on the requirement to book a restaurant, answer each question.
`requirement: {natural language text}`

Question 1: What is the name of the restaurant?
Question 2: How many people mentioned in the requirement for booking?
Question 3: At what time is this booking for?
Question 4: Is there any type of allergy mentioned in the requirement? Choose from [milk, egg, fish, peanuts].

Return your responses in JSON format, using the question number as the key and
the answer as the value.
</code></pre><p>Explain</p>
<ul>
<li>In the prompt, I start by giving a brief overview of the natural language text, setting the tone for the entire prompt or the system role.</li>
<li>List Question #, very likely you will have multiple params to decide.</li>
<li>For each question, I start with a description of the parameter itself. For instance, inquire about the restaurant&rsquo;s name and the number of people mentioned for the booking.</li>
<li>In each question, I started with a description of the param itself. For example, the name of the restaurant, how many people mentioned the booking.
<ul>
<li>In the engineering world, the challenges are usually more intricate than the example we&rsquo;re using here. This is because the parameters of a function are specific to the system itself, often not simple phrases easily understood by the literary word. Teaching LLM, to grasp the meaning or motivation behind these parameters requires careful consideration and is a critical step to success.</li>
</ul>
</li>
<li>If the expected values for a parameter are limited options, resembling a standard enum parameter, it&rsquo;s essential to list the available selections. If necessary, explain the meaning of each value to ensure the LLM can distinguish between them and choose the right one.</li>
<li>Simultaneously, list other requirements for this selection, such as a default value if needed or any dependencies on other questions.</li>
<li>As is customary with LLMs, we encourage the model to return a JSON-formatted response.</li>
</ul>
<h2 id="issues-to-improve">Issues to Improve<a hidden class="anchor" aria-hidden="true" href="#issues-to-improve">#</a></h2>
<p>Yet, the prompt engineering approach has its flaws. A recurring problem is hallucination. Despite instructing the LLM to choose a value from a specified list, it may still generate an unexpected value based on its own interpretation.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="http://matrixstone.github.io/">Matrix Engineering Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
